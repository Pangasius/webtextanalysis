{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will use an RNN architecture to build a Machine Translation model.\n",
    "\n",
    "It will use as a corpus wikipedia dumps.\n",
    "\n",
    "Either the source or the target will be English. We will, in our case, try English to French Translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/lize/.local/lib/python3.10/site-packages (1.23.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cu117\n",
      "Requirement already satisfied: torch in /home/lize/.local/lib/python3.10/site-packages (1.14.0.dev20221115+cu117)\n",
      "Requirement already satisfied: torchvision in /home/lize/.local/lib/python3.10/site-packages (0.15.0.dev20221115+cu117)\n",
      "Requirement already satisfied: torchaudio in /home/lize/.local/lib/python3.10/site-packages (0.14.0.dev20221115+cu117)\n",
      "Requirement already satisfied: typing-extensions in /usr/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /home/lize/.local/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/lize/.local/lib/python3.10/site-packages (from torch) (3.0rc1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3.10/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in /home/lize/.local/lib/python3.10/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.10/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/lize/.local/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/lize/.local/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: transformers in /home/lize/.local/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: d2l==1.0.0a1.post0 in /home/lize/.local/lib/python3.10/site-packages (1.0.0a1.post0)\n",
      "Requirement already satisfied: matplotlib in /home/lize/.local/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (3.6.2)\n",
      "Requirement already satisfied: pandas in /home/lize/.local/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/lize/.local/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (0.1.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (2.28.1)\n",
      "Requirement already satisfied: gym in /home/lize/.local/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (0.26.2)\n",
      "Requirement already satisfied: numpy in /home/lize/.local/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (1.23.4)\n",
      "Requirement already satisfied: jupyter in /home/lize/.local/lib/python3.10/site-packages (from d2l==1.0.0a1.post0) (1.0.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/lize/.local/lib/python3.10/site-packages (from gensim) (6.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/lize/.local/lib/python3.10/site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/lize/.local/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/lize/.local/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/lize/.local/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /home/lize/.local/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lize/.local/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/lize/.local/lib/python3.10/site-packages (from gym->d2l==1.0.0a1.post0) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/lize/.local/lib/python3.10/site-packages (from gym->d2l==1.0.0a1.post0) (2.2.0)\n",
      "Requirement already satisfied: nbconvert in /home/lize/.local/lib/python3.10/site-packages (from jupyter->d2l==1.0.0a1.post0) (7.2.5)\n",
      "Requirement already satisfied: jupyter-console in /home/lize/.local/lib/python3.10/site-packages (from jupyter->d2l==1.0.0a1.post0) (6.4.4)\n",
      "Requirement already satisfied: ipykernel in /home/lize/.local/lib/python3.10/site-packages (from jupyter->d2l==1.0.0a1.post0) (6.16.0)\n",
      "Requirement already satisfied: ipywidgets in /home/lize/.local/lib/python3.10/site-packages (from jupyter->d2l==1.0.0a1.post0) (8.0.2)\n",
      "Requirement already satisfied: qtconsole in /home/lize/.local/lib/python3.10/site-packages (from jupyter->d2l==1.0.0a1.post0) (5.4.0)\n",
      "Requirement already satisfied: notebook in /home/lize/.local/lib/python3.10/site-packages (from jupyter->d2l==1.0.0a1.post0) (6.5.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lize/.local/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0a1.post0) (4.37.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0a1.post0) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lize/.local/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0a1.post0) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lize/.local/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0a1.post0) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/lize/.local/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0a1.post0) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/lize/.local/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0a1.post0) (1.0.5)\n",
      "Requirement already satisfied: traitlets in /home/lize/.local/lib/python3.10/site-packages (from matplotlib-inline->d2l==1.0.0a1.post0) (5.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lize/.local/lib/python3.10/site-packages (from pandas->d2l==1.0.0a1.post0) (2022.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests->d2l==1.0.0a1.post0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.10/site-packages (from requests->d2l==1.0.0a1.post0) (1.26.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->d2l==1.0.0a1.post0) (1.16.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/lize/.local/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (7.4.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/lize/.local/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/lize/.local/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (6.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/lize/.local/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (24.0.1)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (5.9.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/lize/.local/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (8.5.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/lize/.local/lib/python3.10/site-packages (from ipykernel->jupyter->d2l==1.0.0a1.post0) (1.6.3)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/lize/.local/lib/python3.10/site-packages (from ipywidgets->jupyter->d2l==1.0.0a1.post0) (3.0.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/lize/.local/lib/python3.10/site-packages (from ipywidgets->jupyter->d2l==1.0.0a1.post0) (4.0.3)\n",
      "Requirement already satisfied: pygments in /usr/lib/python3.10/site-packages (from jupyter-console->jupyter->d2l==1.0.0a1.post0) (2.13.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/lize/.local/lib/python3.10/site-packages (from jupyter-console->jupyter->d2l==1.0.0a1.post0) (3.0.31)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (0.7.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (2.0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (4.11.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (3.1.2)\n",
      "Requirement already satisfied: bleach in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (5.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (4.11.1)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (5.7.0)\n",
      "Requirement already satisfied: defusedxml in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (1.2.1)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (2.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/lize/.local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0a1.post0) (0.2.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/lize/.local/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0a1.post0) (0.17.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/lize/.local/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0a1.post0) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/lize/.local/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0a1.post0) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/lize/.local/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0a1.post0) (0.15.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/lize/.local/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0a1.post0) (0.4.8)\n",
      "Requirement already satisfied: ipython-genutils in /home/lize/.local/lib/python3.10/site-packages (from notebook->jupyter->d2l==1.0.0a1.post0) (0.2.0)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /home/lize/.local/lib/python3.10/site-packages (from qtconsole->jupyter->d2l==1.0.0a1.post0) (2.3.0)\n",
      "Requirement already satisfied: stack-data in /home/lize/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.5.1)\n",
      "Requirement already satisfied: decorator in /home/lize/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/lize/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/lize/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/lize/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.7.5)\n",
      "Requirement already satisfied: entrypoints in /home/lize/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.4)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /home/lize/.local/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0a1.post0) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/lize/.local/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0a1.post0) (1.23.2)\n",
      "Requirement already satisfied: fastjsonschema in /home/lize/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0a1.post0) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/lize/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0a1.post0) (4.17.0)\n",
      "Requirement already satisfied: wcwidth in /home/lize/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l==1.0.0a1.post0) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /usr/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter->d2l==1.0.0a1.post0) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/lize/.local/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter->d2l==1.0.0a1.post0) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/lize/.local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter->d2l==1.0.0a1.post0) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/lib/python3.10/site-packages (from bleach->nbconvert->jupyter->d2l==1.0.0a1.post0) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/lize/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0a1.post0) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/lize/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0a1.post0) (0.19.2)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /home/lize/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0a1.post0) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /home/lize/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0a1.post0) (1.4.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0a1.post0) (1.15.1)\n",
      "Requirement already satisfied: asttokens in /home/lize/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (2.0.8)\n",
      "Requirement already satisfied: pure-eval in /home/lize/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/lize/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->d2l==1.0.0a1.post0) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lize/.local/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0a1.post0) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0a1.post0) (2.21)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "!pip3 install numpy\n",
    "!pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu117\n",
    "#or any nightly version so long as pytorch > 1.11 https://pytorch.org/\n",
    "!pip3 install gensim transformers d2l==1.0.0a1.post0\n",
    "\n",
    "#In pytorch functional.py, change PILLOW_VERSION to __version__\n",
    "#there are two places to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test samples location and preprocessing\n",
    "\n",
    "#cell almost entirely from https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html\n",
    "import os\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class MTFraEng(d2l.DataModule):  #@save\n",
    "    def _download(self):\n",
    "        d2l.extract(d2l.download(\n",
    "            d2l.DATA_URL+'fra-eng.zip', self.root,\n",
    "            '94646ad1522d915e7b0f9296181140edcf86a4f5'))\n",
    "        with open(self.root + '/fra-eng/fra.txt', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def _preprocess(self, text):\n",
    "    # Replace non-breaking space with space\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "    # Insert space between words and punctuation marks\n",
    "    no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text.lower())]\n",
    "    return ''.join(out)\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def _tokenize(self, text, max_examples=None):\n",
    "    src, tgt = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if max_examples and i > max_examples: break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            # Skip empty tokens\n",
    "            src.append([t for t in f'{parts[0]} <eos>'.split(' ') if t])  # src.append(EOS_token) ? \n",
    "            tgt.append([t for t in f'{parts[1]} <eos>'.split(' ') if t])\n",
    "    return src, tgt\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def __init__(self, batch_size, num_steps=15, num_train=162000, num_test=4000):  #15, 162000\n",
    "    super(MTFraEng, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    self.arrays, self.src_vocab, self.tgt_vocab = self._build_arrays(\n",
    "        self._download())\n",
    "\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):\n",
    "    def _build_array(sentences, vocab, is_tgt=False):\n",
    "        pad_or_trim = lambda seq, t: (\n",
    "            seq[:t] if len(seq) > t else seq + ['<pad>'] * (t - len(seq)))\n",
    "        sentences = [pad_or_trim(s, self.num_steps) for s in sentences]\n",
    "        if is_tgt:\n",
    "            sentences = [['<bos>'] + s for s in sentences]\n",
    "        if vocab is None:\n",
    "            vocab = d2l.Vocab(sentences, min_freq=2)\n",
    "        array = torch.tensor([vocab[s] for s in sentences])\n",
    "        valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "        return array, vocab, valid_len\n",
    "    src, tgt = self._tokenize(self._preprocess(raw_text),\n",
    "                              self.num_train)\n",
    "    src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)\n",
    "    tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True)\n",
    "    return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]),\n",
    "            src_vocab, tgt_vocab)\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def get_dataloader(self, train):\n",
    "    idx = slice(0, self.num_train - self.num_test) if train else slice(self.num_train - self.num_test, self.num_train)\n",
    "    return self.get_tensorloader(self.arrays, train, idx)\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def build(self, src_sentences, tgt_sentences):\n",
    "    raw_text = '\\n'.join([src + '\\t' + tgt for src, tgt in zip(\n",
    "        src_sentences, tgt_sentences)])\n",
    "    arrays, _, _ = self._build_arrays(\n",
    "        raw_text, self.src_vocab, self.tgt_vocab)\n",
    "    return arrays\n",
    "\n",
    "#src, tgt, _,  _ = data.build(['hi .'], ['salut .'])\n",
    "#print('source:', data.src_vocab.to_tokens(src[0].type(torch.int32)))\n",
    "#print('target:', data.tgt_vocab.to_tokens(tgt[0].type(torch.int32)))\n",
    "\n",
    "@d2l.add_to_class(MTFraEng)  #@save\n",
    "def shuffle(self, train, seed, maxi):\n",
    "    if (maxi > self.num_train):\n",
    "        raise ValueError(\"maxi must be less than the length of the dataset\")\n",
    "    \n",
    "    for array in self.arrays:\n",
    "        array = array[0:maxi]\n",
    "        \n",
    "    self.num_train = maxi\n",
    "    self.num_test = int(maxi * 0.3)\n",
    "    \n",
    "    idx = torch.randperm(generator=torch.Generator().manual_seed(seed), n=maxi)\n",
    "    if (not train):\n",
    "        idx = idx[int(maxi * 0.7):]\n",
    "    else :\n",
    "        idx = idx[:int(maxi * 0.7)]\n",
    "    return self.get_tensorloader(self.arrays, train, idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "data = MTFraEng(batch_size=batch_size)\n",
    "\n",
    "usage_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "31600\n",
      "140\n",
      "60\n",
      "60\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(data.get_dataloader(train=False)))\n",
    "print(len(data.get_dataloader(train=True)))\n",
    "print(len(data.shuffle(train=True, seed=0, maxi=usage_size)))\n",
    "print(len(data.shuffle(train=False, seed=0, maxi=usage_size)))\n",
    "print(len(data.get_dataloader(train=False)))\n",
    "print(len(data.get_dataloader(train=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding\n",
    "\n",
    "# We will use three different types of word embeddings:\n",
    "# 1. Word2Vec\n",
    "# 2. GloVe\n",
    "# 3. FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Word2Vec\"\"\"\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4011\n",
      "/home/lize/Desktop/MASTER2/Web_Text_Analysis/webtextanalysis\n",
      "/home/lize/.local/lib/python3.10/site-packages/ipykernel_launcher.py\n"
     ]
    }
   ],
   "source": [
    "#keep in mind you have to launch the notebook inside the git folder to make this work (second one)\n",
    "from inspect import getsourcefile\n",
    "import sys\n",
    "print(os.path.dirname(getsourcefile(lambda:0)))\n",
    "print(sys.path[0])\n",
    "print(os.path.abspath(sys.argv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: tensor([[3681,   72,  187,  188,  188,  188,  188,  188,  188,  188,  188,  188,\n",
      "          188,  188,  188]], dtype=torch.int32)\n",
      "decoder input: tensor([[  136, 15923,     0,   137,   138,   138,   138,   138,   138,   138,\n",
      "           138,   138,   138,   138,   138]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "src, tgt, src_valid_len, label = next(iter(data.shuffle(train=False, seed=0, maxi=1)))\n",
    "print('source:', src.type(torch.int32))\n",
    "print('decoder input:', tgt.type(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_split():\n",
    "    data = MTFraEng(batch_size=5)\n",
    "    with open(\"samples/source.txt\", \"w\") as f:\n",
    "        for i in range(0, data.num_train):\n",
    "            for word in data.arrays[0][i].numpy() :\n",
    "                f.write(str(word) + \" \")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "    with open(\"samples/target.txt\", \"w\") as f:\n",
    "        for i in range(0, data.num_train):\n",
    "            for word in data.arrays[1][i].numpy() :\n",
    "                f.write(str(word) + \" \")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "def load_source():\n",
    "    return np.loadtxt(\"samples/source.txt\", dtype=str)\n",
    "\n",
    "def load_target():\n",
    "    return np.loadtxt(\"samples/target.txt\", dtype=str)\n",
    "\n",
    "def word_to_token(word, src=True):\n",
    "    if src :\n",
    "        return data.src_vocab[word]\n",
    "    else :\n",
    "        return data.tgt_vocab[word]\n",
    "\n",
    "def token_to_word(token, src=True):\n",
    "    if src :\n",
    "        return data.src_vocab.to_tokens(token)\n",
    "    else :\n",
    "        return data.tgt_vocab.to_tokens(token)\n",
    "\n",
    "def test_similarity(model, word1, word2, model_name, src=True):\n",
    "    print(\"Cosine similarity between '\" + word1 + \"' and '\"+ word2 +\"' - \" + model_name + \" : \" + str(model.similarity(word_to_token(word1, src), word_to_token(word2, src))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['hi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['run', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['run', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['who', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'va', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'salut', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'cours', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'courez', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'qui', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "#print a few samples\n",
    "for i in range(5):\n",
    "    print(token_to_word(data.arrays[0][i].numpy(), True))\n",
    "\n",
    "for i in range(5):\n",
    "    print(token_to_word(data.arrays[1][i].numpy(), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(sys.path[0] + \"/samples/source.txt\") or not os.path.exists(sys.path[0] + \"/samples/target.txt\"):\n",
    "    save_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3681'], ['72'], ['187'], ['188']]\n",
      "['go', '.', '<eos>', '<pad>']\n",
      "[['136'], ['15923'], ['0'], ['137']]\n",
      "['<bos>', 'va', '!', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_text = load_source()\n",
    "one_line_source = source_text.reshape([np.prod(source_text.shape)])\n",
    "\n",
    "#format to be accepted by Word2Vec\n",
    "one_line_source = [str(i).split() for i in one_line_source]\n",
    "\n",
    "print(one_line_source[:4])\n",
    "#print in words \n",
    "print([token_to_word(int(i[0]), src=True) for i in one_line_source[:4]])\n",
    "\n",
    "\n",
    "\n",
    "target_text = load_target()\n",
    "one_line_target = target_text.reshape([np.prod(target_text.shape)])\n",
    "\n",
    "#format to be accepted by Word2Vec\n",
    "one_line_target = [str(i).split() for i in one_line_target]\n",
    "\n",
    "print(one_line_target[:4])\n",
    "#print in words \n",
    "print([token_to_word(int(i[0]), src=False) for i in one_line_target[:4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3681'], ['72'], ['187'], ['188'], ['188']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"## Word2Vec\"\"\"\n",
    "\n",
    "print(one_line_source[:5])\n",
    "\n",
    "if not os.path.exists(sys.path[0] + \"/models/source_w2v_cbow.txt\"):\n",
    "    # Create CBOW model\n",
    "    source_w2v_model_cbow = gensim.models.Word2Vec(one_line_source, min_count = 3,\n",
    "                                vector_size = 100, window = 5).wv\n",
    "\n",
    "if not os.path.exists(sys.path[0] + \"/models/source_w2v_skip.txt\"):\n",
    "    # Create Skip Gram model\n",
    "    source_w2v_model_skip = gensim.models.Word2Vec(one_line_source, min_count = 3, vector_size = 100,\n",
    "                                                window = 5, sg = 1).wv\n",
    "    \n",
    "if not os.path.exists(sys.path[0] + \"/models/target_w2v_cbow.txt\"):\n",
    "    # Create CBOW model\n",
    "    target_w2v_model_cbow = gensim.models.Word2Vec(one_line_target, min_count = 3,\n",
    "                                vector_size = 100, window = 5).wv\n",
    "\n",
    "if not os.path.exists(sys.path[0] + \"/models/target_w2v_skip.txt\"):\n",
    "    # Create Skip Gram model\n",
    "    target_w2v_model_skip = gensim.models.Word2Vec(one_line_target, min_count = 3, vector_size = 100,\n",
    "                                                window = 5, sg = 1).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models\n",
    "if not os.path.exists(sys.path[0] + \"/models/source_w2v_cbow.txt\"):\n",
    "    source_w2v_model_cbow.save_word2vec_format(sys.path[0] + \"/models/source_w2v_cbow.txt\", binary=False)\n",
    "    \n",
    "if not os.path.exists(sys.path[0] + \"/models/source_w2v_skip.txt\"):\n",
    "    source_w2v_model_skip.save_word2vec_format(sys.path[0] + \"/models/source_w2v_skip.txt\", binary=False)\n",
    "    \n",
    "if not os.path.exists(sys.path[0] + \"/models/target_w2v_cbow.txt\"):\n",
    "    target_w2v_model_cbow.save_word2vec_format(sys.path[0] + \"/models/target_w2v_cbow.txt\", binary=False)\n",
    "\n",
    "if not os.path.exists(sys.path[0] + \"/models/target_w2v_skip.txt\"):\n",
    "    target_w2v_model_skip.save_word2vec_format(sys.path[0] + \"/models/target_w2v_skip.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the models\n",
    "source_w2v_model_cbow = gensim.models.KeyedVectors.load_word2vec_format(sys.path[0] + \"/models/source_w2v_cbow.txt\", binary=False)\n",
    "source_w2v_model_skip = gensim.models.KeyedVectors.load_word2vec_format(sys.path[0] + \"/models/source_w2v_skip.txt\", binary=False)\n",
    "target_w2v_model_cbow = gensim.models.KeyedVectors.load_word2vec_format(sys.path[0] + \"/models/target_w2v_cbow.txt\", binary=False)\n",
    "target_w2v_model_skip = gensim.models.KeyedVectors.load_word2vec_format(sys.path[0] + \"/models/target_w2v_skip.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'hi' and '.' - CBOW : -0.03504046\n",
      "Cosine similarity between 'hi' and 'run' - CBOW : -0.0359637\n",
      "Cosine similarity between 'hi' and '.' - SkipGram : -0.03504046\n",
      "Cosine similarity between 'hi' and 'run' - SkipGram : -0.0359637\n",
      "Cosine similarity between 'bonjour' and '.' - CBOW : 0.24336207\n",
      "Cosine similarity between 'bonjour' and 'cours' - CBOW : 1.0\n",
      "Cosine similarity between 'bonjour' and '.' - CBOW : 0.24336207\n",
      "Cosine similarity between 'bonjour' and 'cours' - CBOW : 1.0\n"
     ]
    }
   ],
   "source": [
    "test_similarity(source_w2v_model_cbow, 'hi', '.', \"CBOW\")\n",
    "test_similarity(source_w2v_model_cbow, 'hi', 'run', \"CBOW\")\n",
    "\n",
    "test_similarity(source_w2v_model_skip, 'hi', '.', \"SkipGram\")\n",
    "test_similarity(source_w2v_model_skip, 'hi', 'run', \"SkipGram\")\n",
    "\n",
    "test_similarity(target_w2v_model_cbow, 'bonjour', '.', \"CBOW\")\n",
    "test_similarity(target_w2v_model_cbow, 'bonjour', 'cours', \"CBOW\")\n",
    "\n",
    "test_similarity(target_w2v_model_skip, 'bonjour', '.', \"CBOW\")\n",
    "test_similarity(target_w2v_model_skip, 'bonjour', 'cours', \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## GloVe\"\"\"\n",
    "\n",
    "# coding: utf-8\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once we have the tokenized file, we can call the glove model\n",
    "\n",
    "####CALL FROM BASH glove_run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only do this once (depends on if windows or linux sometimes)\n",
    "#source_file = sys.path[0] + '\\\\models\\\\source_glove.txt'\n",
    "#target_file = sys.path[0] + '\\\\models\\\\target_glove.txt'\n",
    "\n",
    "source_file = sys.path[0] + '/models/source_glove.txt'\n",
    "target_file = sys.path[0] + '/models/target_glove.txt'\n",
    "# Load the model, can take a bit of time\n",
    "source_glove_model = KeyedVectors.load_word2vec_format(source_file, binary=False, no_header=True)\n",
    "target_glove_model = KeyedVectors.load_word2vec_format(source_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'hi' and '.' - GloVe : -0.010622903\n",
      "Cosine similarity between 'hi' and 'run' - GloVe : 0.21301486\n",
      "Cosine similarity between 'bonjour' and '.' - GloVe : -0.04953654\n",
      "Cosine similarity between 'bonjour' and 'cours' - GloVe : 0.504102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "test_similarity(source_glove_model, 'hi', '.', \"GloVe\", src=True)\n",
    "test_similarity(source_glove_model, 'hi', 'run', \"GloVe\", src=True)\n",
    "\n",
    "test_similarity(target_glove_model, 'bonjour', '.', \"GloVe\", src=False)\n",
    "test_similarity(target_glove_model, 'bonjour', 'cours', \"GloVe\", src=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## FastText\"\"\"\n",
    "from gensim.models import FastText\n",
    "\n",
    "#if not saved yet we train it\n",
    "if not os.path.exists(sys.path[0] + \"/models/source_fast.txt\"):\n",
    "    source_fast_model = FastText(vector_size=100, window=5, min_count=3)\n",
    "    source_fast_model.build_vocab(corpus_file=sys.path[0] + '/samples/source.txt')\n",
    "    source_fast_model.train(corpus_file=sys.path[0] + '/samples/source.txt', epochs=10, total_examples=source_fast_model.corpus_count, total_words=source_fast_model.corpus_total_words)\n",
    "    source_fast_model = source_fast_model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(sys.path[0] + \"/models/target_fast.txt\"):\n",
    "    target_fast_model = FastText(vector_size=100, window=5, min_count=3)\n",
    "    target_fast_model.build_vocab(corpus_file=sys.path[0] + '/samples/target.txt')\n",
    "    target_fast_model.train(corpus_file=sys.path[0] + '/samples/target.txt', epochs=10, total_examples=target_fast_model.corpus_count, total_words=target_fast_model.corpus_total_words)\n",
    "    target_fast_model = target_fast_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(sys.path[0] + \"/models/source_fast.txt\"):\n",
    "    source_fast_model.save_word2vec_format(sys.path[0] + \"/models/source_fast.txt\", binary=False)\n",
    "if not os.path.exists(sys.path[0] + \"/models/target_fast.txt\"):\n",
    "    target_fast_model.save_word2vec_format(sys.path[0] + \"/models/target_fast.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if saved we load it\n",
    "source_fast_model = KeyedVectors.load_word2vec_format(sys.path[0] + \"/models/source_fast.txt\", binary=False)\n",
    "target_fast_model = KeyedVectors.load_word2vec_format(sys.path[0] + \"/models/target_fast.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'hi' and '.' - FastText : 0.1312445\n",
      "Cosine similarity between 'hi' and 'run' - FastText : 0.55649316\n",
      "Cosine similarity between 'bonjour' and '.' - FastText : 0.11566037\n",
      "Cosine similarity between 'bonjour' and 'cours' - FastText : 0.61512697\n"
     ]
    }
   ],
   "source": [
    "test_similarity(source_fast_model,'hi', '.', \"FastText\", src=True)\n",
    "test_similarity(source_fast_model,'hi', 'run', \"FastText\", src=True)\n",
    "\n",
    "test_similarity(target_fast_model,'bonjour', '.', \"FastText\", src=False)\n",
    "test_similarity(target_fast_model,'bonjour', 'cours', \"FastText\", src=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the RNN model that will translate from english to french using one of the previous embeddings\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN_encode(nn.Module):\n",
    "    def __init__(self, embedding_model_input, embedding_model_output):\n",
    "        super(RNN_encode, self).__init__()\n",
    "\n",
    "        self.embedding_in = embedding_model_input\n",
    "        self.embedding_out = embedding_model_output\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.embedding_dim_in = embedding_model_input.vector_size\n",
    "        self.lstm_in = nn.LSTM(self.embedding_dim_in, self.embedding_dim_in, bidirectional=True)\n",
    "        self.hidden_in = nn.Linear(self.embedding_dim_in * 2, self.embedding_dim_in)\n",
    "\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        #words_embeddings is a gensim model\n",
    "        embeds = torch.tensor(np.array([[self.embedding_in[int(word.item())] if int(word.item()) in self.embedding_in else self.embedding_in.vectors.mean(axis=0) for word in sentence] for sentence in input_sentence]), requires_grad=True).to(device)\n",
    "        \n",
    "        #encoder\n",
    "        output_lstm_1, _ = self.lstm_in(embeds.view(input_sentence.shape[0], input_sentence.shape[1], self.embedding_dim_in))\n",
    "        output_hidden_1 = self.hidden_in(output_lstm_1.view(input_sentence.shape[0], input_sentence.shape[1], self.embedding_dim_in * 2))\n",
    "        \n",
    "        return F.log_softmax(output_hidden_1, dim=2)\n",
    "        \n",
    "\n",
    "    \n",
    "class RNN_decode(nn.Module):\n",
    "    def __init__(self, embedding_model_input, embedding_model_output):\n",
    "        super(RNN_decode, self).__init__()\n",
    "\n",
    "        self.embedding_in = embedding_model_input\n",
    "        self.embedding_out = embedding_model_output\n",
    "        \n",
    "        self.embedding_dim_in = embedding_model_input.vector_size\n",
    "        self.embedding_dim_out = embedding_model_input.vector_size\n",
    "        print(self.embedding_dim_out)\n",
    "        self.lstm_out = nn.LSTM(self.embedding_dim_in, self.embedding_dim_out, bidirectional=True)\n",
    "        self.hidden_out = nn.Linear(self.embedding_dim_out * 2, self.embedding_dim_out)\n",
    "        \n",
    "    def forward(self, hidden_sentence):\n",
    "        #decoder\n",
    "        output_lstm_2, _ = self.lstm_out(hidden_sentence.view(hidden_sentence.shape[0], hidden_sentence.shape[1], self.embedding_dim_in))\n",
    "        output_hidden_2 = self.hidden_out(output_lstm_2.view(hidden_sentence.shape[0], hidden_sentence.shape[1], self.embedding_dim_out * 2))\n",
    "        \n",
    "        out = torch.abs(torch.matmul(output_hidden_2, self.embedding_out.transpose(0,1)))\n",
    "        \n",
    "        #5, 15, VOCAB_SIZE\n",
    "        \n",
    "        #where output  greater than length of embedding_out[1] we set it to unknown\n",
    "        soft =  F.softmax(out, dim=2)\n",
    "        \n",
    "        return (soft @ self.embedding_out) # VOCAB_SIZE * EMBEDDING_DIM\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_model_input, embedding_model_output):\n",
    "        super(RNN, self).__init__()\n",
    "        self.encoder = RNN_encode(embedding_model_input, embedding_model_output)\n",
    "        self.decoder = RNN_decode(embedding_model_input, embedding_model_output)\n",
    "        \n",
    "    def forward(self, input_sentence):\n",
    "        hidden_sentence = self.encoder(input_sentence)\n",
    "        output_sentence = self.decoder(hidden_sentence)\n",
    "        return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From this model we can create a loss function and an optimizer\n",
    "\n",
    "def loss_function(predicted_sentence, target_sentence, embedder):\n",
    "    \n",
    "    loss = torch.zeros(1, requires_grad=True).to(device)\n",
    "    for i in range(target_sentence.shape[0]):\n",
    "        for j in range(target_sentence.shape[1]):\n",
    "            if int(target_sentence[i][j]) < embedder.shape[0]:\n",
    "                loss = loss + torch.abs(torch.matmul(predicted_sentence[i][j], embedder[int(target_sentence[i][j])])) \n",
    "            \n",
    "\n",
    "    return loss / (target_sentence.shape[0] * target_sentence.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Ready\n",
      "Epoch: 0/5............. Loss: 0.02104993909597397............. time : 0.20898439557854157\n",
      "Epoch: 1/5............. Loss: 0.02686382830142975.............time : 0.194389903924375338\n",
      "Epoch: 2/5............. Loss: 0.019532058387994766.............time : 0.20087348498995092\n",
      "Epoch: 3/5............. Loss: 0.02198929712176323............. time : 0.20607674177145624\n",
      "Epoch: 4/5............. Loss: 0.021459616720676422.............time : 0.20223299579766965\n"
     ]
    }
   ],
   "source": [
    "#Now we can train the model\n",
    "import torch\n",
    "import time\n",
    "\n",
    "embed_in = source_fast_model\n",
    "embed_out = target_fast_model\n",
    "\n",
    "embedding_out = torch.tensor(embed_out.vectors, requires_grad=False).to(device)\n",
    "embedding_out = torch.transpose(embedding_out.transpose(0,1) / torch.norm(embedding_out, dim=1), 0, 1)\n",
    "\n",
    "model = RNN(embedding_model_input=embed_in, embedding_model_output=embedding_out).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epoch = 5\n",
    "\n",
    "size_per_epoch = int(usage_size * 0.7 / batch_size) + 1\n",
    "\n",
    "print(\"Ready\")\n",
    "\n",
    "def train() :\n",
    "    epoch_loss = np.zeros(n_epoch)\n",
    "    for epoch in range(n_epoch):\n",
    "        counter = 0\n",
    "        time_avg = 0\n",
    "        for src, tgt, src_valid_len, label in data.shuffle(train=True, seed=0, maxi=usage_size):\n",
    "            time_start = time.time()\n",
    "            \n",
    "            src.to(device)\n",
    "            tgt.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tag_scores = model(src)\n",
    "\n",
    "            loss = loss_function(tag_scores, tgt, embedding_out)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print(\"grad of lstm in\"  + str(model.encoder.lstm_in.weight_hh_l0.grad))\n",
    "\n",
    "            counter += 1\n",
    "            time_avg = time_avg * 0.95 + (time.time() - time_start) * (size_per_epoch - counter) * 0.01\n",
    "            print(\"New step : \", counter, \"/\", size_per_epoch, \" loss : \", loss.item(), \" estimated time :\", time_avg , end=\"\\r\")\n",
    "            \n",
    "        #here we can use the test data to evaluate the model\n",
    "        with torch.no_grad() :\n",
    "            losses = torch.zeros(int(usage_size * 0.3 / batch_size) + 1)\n",
    "            counter = 0\n",
    "            for src, tgt, src_valid_len, label in data.shuffle(train=False, seed=0, maxi=usage_size):\n",
    "                src.to(device)\n",
    "                tgt.to(device)\n",
    "\n",
    "                tag_scores = model(src)\n",
    "\n",
    "                loss = loss_function(tag_scores, tgt, embedding_out)\n",
    "                \n",
    "                losses[counter] = loss.item()\n",
    "                counter += 1\n",
    "\n",
    "            epoch_loss[epoch] = losses.mean()\n",
    "            print(\"Epoch: {}/{}.............\".format(epoch, n_epoch), end=\" \")\n",
    "            print(\"Loss: \" + str(epoch_loss[epoch]) + \".............\")\n",
    "            \n",
    "    return epoch_loss\n",
    "            \n",
    "epoch_loss = train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa22879b970>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence : \n",
      "don't lie . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "2602 4866 72 187 188 188 188 188 188 188 188 188 188 188 188 \n",
      "Translated sentence : \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTranslated sentence : \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m tag_scores[\u001b[39m0\u001b[39m]:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mprint\u001b[39m(token_to_word(\u001b[39mint\u001b[39m(word\u001b[39m.\u001b[39;49mitem()), src\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m tag_scores[\u001b[39m0\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "#sample a sentence from the test set\n",
    "src, tgt, src_valid_len, label = next(iter(data.shuffle(train=False, seed=0, maxi=usage_size)))\n",
    "\n",
    "#translate the sentence\n",
    "\n",
    "sentence = src.to(device)\n",
    "\n",
    "tag_scores = model(sentence)\n",
    "\n",
    "#print the original sentence\n",
    "print(\"Original sentence : \")\n",
    "for word in src[0]:\n",
    "    print(token_to_word(word.item(), src=True), end=\" \")\n",
    "print()\n",
    "for word in src[0]:\n",
    "    print(word.item(), end=\" \")\n",
    "print()\n",
    "\n",
    "#print the translated sentence\n",
    "print(\"Translated sentence : \")\n",
    "for word in tag_scores[0]:\n",
    "    print(token_to_word(int(word.item()), src=False), end=\" \")\n",
    "print()\n",
    "for word in tag_scores[0]:\n",
    "    print(int(word.item()), end=\" \")\n",
    "print()\n",
    "\n",
    "#print the target sentence\n",
    "print(\"Target sentence : \")\n",
    "for word in tgt[0]:\n",
    "    print(token_to_word(word.item(), src=False), end=\" \")\n",
    "print()\n",
    "for word in tgt[0]:\n",
    "    print(word.item(), end=\" \")\n",
    "print()\n",
    "\n",
    "for word in label[0]:\n",
    "    print(token_to_word(word.item(), src=False), end=\" \")\n",
    "print()\n",
    "for word in label[0]:\n",
    "    print(word.item(), end=\" \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this model we can now try to add contextual embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for contextual embedding we will use BERT\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "#we use bert and we will train it on the data\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "#we will use the tokenizer to tokenize the sentences\n",
    "sentences = [\"I love machine learning\", \"I love coding in python\"]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
